{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/andregabrielmelo/license-plate-detection/blob/main/Jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPsM2GyQtiIS"
   },
   "source": [
    "# Trabalho M2\n",
    "\n",
    "Crie um sistema para localizar os caracteres de placas veículares utilizando as imagens do dataset disponibilizado e seguindo os critérios apresentados no enunciado do trabalho.\n",
    "\n",
    "Abaixo estão códigos auxiliares para manipulação do dataset, visualização e cálculo de métricas.\n",
    "\n",
    "Explore este notebook antes de iniciar o trabalho para um melhor aproveitamento do seu tempo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IXjXlpLptfkD"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from models.label import Label\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Label:\n",
    "    class_id: int\n",
    "    center_y: float\n",
    "    center_x: float\n",
    "    height: float\n",
    "    width: float\n",
    "\n",
    "def draw_bboxes(\n",
    "    img_rgb: cv2.Mat,\n",
    "    labels: list[Label],\n",
    "    color: Tuple,\n",
    "    thickness: int = 2,\n",
    ") -> cv2.Mat:\n",
    "    img_copy = img_rgb.copy()\n",
    "    h, w, _ = img_copy.shape\n",
    "\n",
    "    for lbl in labels:\n",
    "        cx = lbl.center_x\n",
    "        cy = lbl.center_y\n",
    "        bw = lbl.width\n",
    "        bh = lbl.height\n",
    "\n",
    "        # Converter coordenadas YOLO (cx,cy,bw,bh) -> (x_min,y_min,x_max,y_max)\n",
    "        x_min = int((cx - bw / 2) * w)\n",
    "        y_min = int((cy - bh / 2) * h)\n",
    "        x_max = int((cx + bw / 2) * w)\n",
    "        y_max = int((cy + bh / 2) * h)\n",
    "\n",
    "        # Desenhar a bounding box\n",
    "        cv2.rectangle(img_copy, (x_min, y_min), (x_max, y_max), color, thickness)\n",
    "\n",
    "    return img_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Na831VBRuJf7"
   },
   "source": [
    "# Parte principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "Fyuo9T1MuGYS",
    "outputId": "c402134c-b9ea-44ef-9ff9-12650ad0fc18"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from helpers import debug_img, debug_img_individual, draw_bboxes\n",
    "from models.label import Label\n",
    "\n",
    "def localize_char_bbox(\n",
    "    img: cv2.Mat, edge_method: str = \"canny\"\n",
    ") -> Tuple[List[Label], List[dict]]:\n",
    "    \"\"\"\n",
    "    Esta função localiza caracteres da placa usando métodos tradicionais e retorna\n",
    "    bounding boxes normalizadas (YOLO-like).\n",
    "\n",
    "    Notas para o aluno:\n",
    "    1. Você provavelmente terá de testar diferentes métodos até encontrar um que\n",
    "    melhor atenda a tarefa.\n",
    "    2. Bounding boxes normalizadas (YOLO-like) significam que você terá que dividir\n",
    "    o pixel em X pela largura da imagem e o pixel em Y pela altura da imagem\n",
    "    \"\"\"\n",
    "    predictions: List[Label]\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Suavização para reduzir ruído\n",
    "    blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    # TODO: Essas funções deveriam ajudar a aumentar a precisão da detecção de bordas. Descobrir a maneira correta de aplicar elas\n",
    "    # Binarização (threshold adaptativo ou Otsu)\n",
    "    high_thresh, thresh = cv2.threshold(\n",
    "        blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n",
    "    )\n",
    "\n",
    "    # Inverter se necessário (caracteres escuros em fundo claro)\n",
    "    if np.mean(thresh) > 127:\n",
    "        thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "    # Remove little pieces\n",
    "    # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    # clean = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
    "    # clean = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # TODO: Decobrir uma maeira melhor de selecionar o threshold utilizdo\n",
    "    # Edge Detection\n",
    "    if edge_method.lower() == \"canny\":\n",
    "        edges = cv2.Canny(blur, high_thresh * 0.5, high_thresh)\n",
    "\n",
    "    elif edge_method.lower() == \"sobel\":\n",
    "        sobelx = cv2.Sobel(blur, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobely = cv2.Sobel(blur, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        sobel = cv2.magnitude(sobelx, sobely)\n",
    "        sobel = cv2.convertScaleAbs(sobel)\n",
    "        _, edges = cv2.threshold(sobel, 120, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    elif edge_method.lower() == \"laplacian\":\n",
    "        laplacian = cv2.Laplacian(blur, cv2.CV_64F)\n",
    "        laplacian = cv2.convertScaleAbs(laplacian)\n",
    "        _, edges = cv2.threshold(laplacian, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Método inválido. Use 'canny', 'sobel' ou 'laplacian'.\")\n",
    "\n",
    "    combined = cv2.bitwise_or(thresh, edges)\n",
    "\n",
    "    # TODO: Deve ser aplicado uma função para prevenção da junção das bordas\n",
    "\n",
    "    # Contour Detection\n",
    "    contours, hierarchy = cv2.findContours(\n",
    "        combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    h_img, w_img = img.shape[:2]\n",
    "\n",
    "    # TODO: Descobrir o porque as predições não estão corretas, mesmo pegado os contornos corretos de algumas imagens\n",
    "\n",
    "    predictions = []\n",
    "    for contour in contours:\n",
    "        # TODO: Melhorar heuristica\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # Heurísticas para filtrar caracteres\n",
    "        if heuristic(contour, img):\n",
    "            cx = (x + w / 2) / w_img\n",
    "            cy = (y + h / 2) / h_img\n",
    "            predictions.append(\n",
    "                Label(\n",
    "                    class_id=0,\n",
    "                    center_x=cx,\n",
    "                    center_y=cy,\n",
    "                    width=w / w_img,\n",
    "                    height=h / h_img,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # 6. Ordenar da esquerda para direita (opcional)\n",
    "    predictions.sort(key=lambda l: l.center_x)\n",
    "\n",
    "    # # Make a copy of the original image to draw contours on\n",
    "    img_contours = img.copy()\n",
    "    cv2.drawContours(img_contours, contours, -1, (0, 255, 0), 1)\n",
    "    img_contours_rgb = cv2.cvtColor(img_contours, cv2.COLOR_BGR2RGB)\n",
    "    images_process = [\n",
    "        {\"image\": gray, \"title\": \"Grey\"},\n",
    "        {\"image\": blur, \"title\": \"Blur\"},\n",
    "        {\"image\": thresh, \"title\": \"Thresh binarização\"},\n",
    "        {\"image\": edges, \"title\": \"Edges\" + f\" {edge_method}\"},\n",
    "        {\"image\": img_contours_rgb, \"title\": \"Detected Contours\"},\n",
    "    ]\n",
    "\n",
    "    return (predictions, images_process)\n",
    "\n",
    "def heuristic(contour, img):\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    aspect_ratio = w / h\n",
    "    area = w * h\n",
    "    h_img, w_img = img.shape[:2]\n",
    "\n",
    "    if 0.2 < aspect_ratio < 1.2 and 0.01 * h_img * w_img < area < 0.2 * h_img * w_img:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def load_data(dir_path: str):\n",
    "    \"\"\"\n",
    "    Load image data from directory `data_dir`.\n",
    "\n",
    "    Return tuple `(images, labels)`. `images` should be a list of all\n",
    "    of the images in the data directory, where each image is formatted as a\n",
    "    open cv MatLike. `labels` should be a list of with a list of labels,\n",
    "    representing the list of labels for each of the corresponding `images`.\n",
    "    Each image has one label per character in the license plate.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get path\n",
    "    dataset_dir_path = Path(dir_path)\n",
    "    images_file_path = list(dataset_dir_path.glob(\"*.png\"))\n",
    "    labels_file_path = list(dataset_dir_path.glob(\"*.txt\"))\n",
    "\n",
    "    # Sort\n",
    "    images_file_path.sort()\n",
    "    labels_file_path.sort()\n",
    "\n",
    "    # Pega uma porcentagem do dataset\n",
    "    # size = len(images_file_path)\n",
    "    # images_file_path = images_file_path[0 : int(size * 0.1)]\n",
    "    # labels_file_path = labels_file_path[0 : int(size * 0.1)]\n",
    "\n",
    "    # Get images\n",
    "    images: list[cv2.Mat] = []\n",
    "    for file_path in images_file_path:\n",
    "        image = cv2.imread(str(file_path), cv2.IMREAD_COLOR_RGB)\n",
    "        images.append(image)\n",
    "\n",
    "    # Get labels\n",
    "    labels: list[list[Label]] = []\n",
    "    for file_path in labels_file_path:\n",
    "        file_labels = []\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                cid, cx, cy, w, h = line.split(\" \")\n",
    "                file_labels.append(\n",
    "                    Label(int(cid), float(cy), float(cx), float(h), float(w))\n",
    "                )\n",
    "\n",
    "        labels.append(file_labels)\n",
    "\n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJDjlxhduqN-"
   },
   "source": [
    "# Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4uVJJZkluuB4",
    "outputId": "6557d986-49ab-43c3-8537-c2fd0ad9810b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_iou(bbox1, bbox2):\n",
    "    \"\"\"\n",
    "    Calcula IoU entre dois retângulos (no formato YOLO normalizado).\n",
    "    \"\"\"\n",
    "    # Converter para coordenadas absolutas [xmin, ymin, xmax, ymax]\n",
    "    x1_min = bbox1.center_x - bbox1.width / 2\n",
    "    y1_min = bbox1.center_y - bbox1.height / 2\n",
    "    x1_max = bbox1.center_x + bbox1.width / 2\n",
    "    y1_max = bbox1.center_y + bbox1.height / 2\n",
    "\n",
    "    x2_min = bbox2.center_x - bbox2.width / 2\n",
    "    y2_min = bbox2.center_y - bbox2.height / 2\n",
    "    x2_max = bbox2.center_x + bbox2.width / 2\n",
    "    y2_max = bbox2.center_y + bbox2.height / 2\n",
    "\n",
    "    # Interseção\n",
    "    inter_xmin = max(x1_min, x2_min)\n",
    "    inter_ymin = max(y1_min, y2_min)\n",
    "    inter_xmax = min(x1_max, x2_max)\n",
    "    inter_ymax = min(y1_max, y2_max)\n",
    "\n",
    "    inter_w = max(0, inter_xmax - inter_xmin)\n",
    "    inter_h = max(0, inter_ymax - inter_ymin)\n",
    "    inter_area = inter_w * inter_h\n",
    "\n",
    "    # Áreas individuais\n",
    "    area1 = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "    area2 = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "\n",
    "    # IoU\n",
    "    union = area1 + area2 - inter_area\n",
    "    return inter_area / union if union > 0 else 0\n",
    "\n",
    "\n",
    "def evaluate_iou(detected_labels, true_labels, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calcula métricas médias de IoU e taxa de acerto (detections corretas).\n",
    "    \"\"\"\n",
    "    ious = []\n",
    "    matched = 0\n",
    "\n",
    "    for det in detected_labels:\n",
    "        best_iou = 0\n",
    "        for gt in true_labels:\n",
    "            iou = compute_iou(det, gt)\n",
    "            best_iou = max(best_iou, iou)\n",
    "        ious.append(best_iou)\n",
    "        if best_iou >= iou_threshold:\n",
    "            matched += 1\n",
    "\n",
    "    mean_iou = np.mean(ious) if ious else 0\n",
    "    precision = matched / len(detected_labels) if detected_labels else 0\n",
    "    recall = matched / len(true_labels) if true_labels else 0\n",
    "\n",
    "    return {\"mean_iou\": float(mean_iou), \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQHnLrX3vc52"
   },
   "source": [
    "# Visualização\n",
    "\n",
    "\n",
    "Gere abaixo alguns exemplos de predições do seu método e compare com as respostas esperadas e as respostas do método exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_img(images):\n",
    "    ncols = len(images)\n",
    "    f, axarr = plt.subplots(1, ncols, figsize=(4 * ncols, 4))\n",
    "\n",
    "    # Intermediate steps from localize_char_bbox\n",
    "    for i, step in enumerate(images):\n",
    "        axarr[i].imshow(\n",
    "            step[\"image\"], cmap=\"gray\" if len(step[\"image\"].shape) == 2 else None\n",
    "        )\n",
    "        axarr[i].set_title(step[\"title\"])\n",
    "        axarr[i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQHnLrX3vc52"
   },
   "source": [
    "# Execução principal\n",
    "\n",
    "\n",
    "Código com execução principal, para rodar os demais códgios e calcular as médias de precisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gphhXoE_vddz"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Check command-line arguments\n",
    "    datasetPath = \"\"\n",
    "    if len(sys.argv) in [2, 3]:\n",
    "        datasetPath = sys.argv[1]\n",
    "    else:\n",
    "        datasetPath = \"dataset\"\n",
    "        \n",
    "    # Get image arrays and labels for all image files\n",
    "    images, labels = load_data(datasetPath)\n",
    "\n",
    "    # Evaluate precision\n",
    "    mean_iou = 0\n",
    "    mean_precision = 0\n",
    "    mean_recall = 0\n",
    "\n",
    "    for index, img, label in zip(range(len(images)), images, labels):\n",
    "        # Localize the caharacters of the licese plate in the image\n",
    "        predictions, image_process = localize_char_bbox(img)\n",
    "\n",
    "        metrics = evaluate_iou(predictions, label)\n",
    "        # print(f\"{index} Cannny metrics:\", metrics)\n",
    "\n",
    "        # If precision is too low, try fallback methods\n",
    "        if metrics[\"precision\"] < 0.1:\n",
    "            # Try Laplacian\n",
    "            lap_preds, lap_images = localize_char_bbox(img, edge_method=\"laplacian\")\n",
    "            lap_metrics = evaluate_iou(lap_preds, label)\n",
    "            # print(\"Lapl   acian metrics:\", lap_metrics)\n",
    "\n",
    "            # Try Sobel\n",
    "            sobel_preds, sobel_images = localize_char_bbox(img, edge_method=\"sobel\")\n",
    "            sobel_metrics = evaluate_iou(sobel_preds, label)\n",
    "            # print(\"Sobel metrics:\", sobel_metrics)\n",
    "\n",
    "            # Pick best fallback by precision\n",
    "            best_method = \"laplacian\"\n",
    "            best_preds = lap_preds\n",
    "            best_images = lap_images\n",
    "            best_metrics = lap_metrics\n",
    "\n",
    "            if sobel_metrics[\"precision\"] > best_metrics[\"precision\"]:\n",
    "                best_method = \"sobel\"\n",
    "                best_preds = sobel_preds\n",
    "                best_images = sobel_images\n",
    "                best_metrics = sobel_metrics\n",
    "\n",
    "            # Use best fallback if better than Canny\n",
    "            if best_metrics[\"precision\"] > metrics[\"precision\"]:\n",
    "                predictions = best_preds\n",
    "                image_process = best_images\n",
    "                metrics = best_metrics\n",
    "                # print(f\"Using fallback method: {best_method}\")\n",
    "\n",
    "        imgdraw = draw_bboxes(img, label, color=(0, 255, 0), thickness=1)\n",
    "        imgdraw = draw_bboxes(imgdraw, predictions, color=(255, 0, 0), thickness=1)\n",
    "\n",
    "        image_process.append({\"image\": img, \"title\": \"Original\"})\n",
    "        image_process.append({\"image\": imgdraw, \"title\": \"Detected\"})\n",
    "\n",
    "        # Pegar imagens para relatório\n",
    "        if (\n",
    "            index == 0\n",
    "        ):\n",
    "            debug_img(image_process)\n",
    "\n",
    "        mean_iou += metrics[\"mean_iou\"]\n",
    "        mean_precision += metrics[\"precision\"]\n",
    "        mean_recall += metrics[\"recall\"]\n",
    "\n",
    "    n_samples = len(images)\n",
    "    print()\n",
    "    print(f\"Mean IoU: {mean_iou / n_samples}\")\n",
    "    print(f\"Mean precision: {mean_precision / n_samples}\")\n",
    "    print(f\"Mean recall: {mean_recall / n_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
