{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/andregabrielmelo/license-plate-detection/blob/main/Jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPsM2GyQtiIS",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Trabalho M2\n",
    "\n",
    "Alunos:\n",
    "- Andre Gabriel de Melo\n",
    "- Caio Furtado Rosa\n",
    "- Jordan Lippert de Oliveira\n",
    "- Lucas Bittencourt Rauch\n",
    "\n",
    "Crie um sistema para localizar os caracteres de placas veículares utilizando as imagens do dataset disponibilizado e seguindo os critérios apresentados no enunciado do trabalho.\n",
    "\n",
    "Abaixo estão códigos auxiliares para manipulação do dataset, visualização e cálculo de métricas.\n",
    "\n",
    "Explore este notebook antes de iniciar o trabalho para um melhor aproveitamento do seu tempo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Label:\n",
    "    class_id: int\n",
    "    center_y: float\n",
    "    center_x: float\n",
    "    height: float\n",
    "    width: float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from models.label import Label\n",
    "\n",
    "\n",
    "def draw_bboxes(\n",
    "    img_rgb: cv2.typing.MatLike,\n",
    "    labels: list[Label],\n",
    "    color: Tuple,\n",
    "    thickness: int = 2,\n",
    ") -> cv2.typing.MatLike:\n",
    "    img_copy = img_rgb.copy()\n",
    "    h, w, _ = img_copy.shape\n",
    "\n",
    "    for lbl in labels:\n",
    "        cx = lbl.center_x\n",
    "        cy = lbl.center_y\n",
    "        bw = lbl.width\n",
    "        bh = lbl.height\n",
    "\n",
    "        # Converter coordenadas YOLO (cx,cy,bw,bh) -> (x_min,y_min,x_max,y_max)\n",
    "        x_min = int((cx - bw / 2) * w)\n",
    "        y_min = int((cy - bh / 2) * h)\n",
    "        x_max = int((cx + bw / 2) * w)\n",
    "        y_max = int((cy + bh / 2) * h)\n",
    "\n",
    "        # Desenhar a bounding box\n",
    "        cv2.rectangle(img_copy, (x_min, y_min), (x_max, y_max), color, thickness)\n",
    "\n",
    "    return img_copy\n",
    "\n",
    "\n",
    "def debug_img(images):\n",
    "    ncols = len(images)\n",
    "    f, axarr = plt.subplots(1, ncols, figsize=(4 * ncols, 4))\n",
    "\n",
    "    # Intermediate steps from localize_char_bbox\n",
    "    for i, step in enumerate(images):\n",
    "        axarr[i].imshow(\n",
    "            step[\"image\"], cmap=\"gray\" if len(step[\"image\"].shape) == 2 else None\n",
    "        )\n",
    "        axarr[i].set_title(step[\"title\"])\n",
    "        axarr[i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def debug_img_individual(images):\n",
    "    \"\"\"\n",
    "    Display each image individually with its title.\n",
    "\n",
    "    Parameters:\n",
    "        images (list of dict): List of dictionaries containing\n",
    "            {\n",
    "                \"image\": <numpy.ndarray>,\n",
    "                \"title\": <str>\n",
    "            }\n",
    "    \"\"\"\n",
    "    for step in images:\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(\n",
    "            step[\"image\"], cmap=\"gray\" if len(step[\"image\"].shape) == 2 else None\n",
    "        )\n",
    "        plt.title(step.get(\"title\", \"\"))\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IXjXlpLptfkD"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from helpers import draw_bboxes\n",
    "from models.label import Label\n",
    "\n",
    "\n",
    "def localize_char_bbox(\n",
    "    img: cv2.typing.MatLike, edge_method: str = \"canny\"\n",
    ") -> Tuple[List[Label], List[dict]]:\n",
    "    \"\"\"\n",
    "    Esta função localiza caracteres da placa usando métodos tradicionais e retorna\n",
    "    bounding boxes normalizadas (YOLO-like).\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Suavização para reduzir ruído\n",
    "    blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    # Binarização (threshold adaptativo ou Otsu)\n",
    "    otsu_thresh, thresh = cv2.threshold(\n",
    "        blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n",
    "    )\n",
    "\n",
    "    # Inverter cor dos pixels caso necessário (caracteres escuros em fundo claro)\n",
    "    if np.mean(thresh) > 127:\n",
    "        thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "    # Detecção de bordas\n",
    "    if edge_method.lower() == \"canny\":\n",
    "        edges = cv2.Canny(blur, otsu_thresh * 0.5, otsu_thresh)\n",
    "\n",
    "    elif edge_method.lower() == \"sobel\":\n",
    "        sobelx = cv2.Sobel(blur, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobely = cv2.Sobel(blur, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        sobel = cv2.magnitude(sobelx, sobely)\n",
    "        sobel = cv2.convertScaleAbs(sobel)\n",
    "        _, edges = cv2.threshold(sobel, 120, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    elif edge_method.lower() == \"laplacian\":\n",
    "        laplacian = cv2.Laplacian(blur, cv2.CV_64F)\n",
    "        laplacian = cv2.convertScaleAbs(laplacian)\n",
    "        _, edges = cv2.threshold(laplacian, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Método inválido. Use 'canny', 'sobel' ou 'laplacian'.\")\n",
    "\n",
    "    # Combinação o método de Otsu junto com a técnica de detecção de bordas escolhido\n",
    "    combined = cv2.bitwise_or(thresh, edges)\n",
    "\n",
    "    # Detecção de contorno\n",
    "    contours, hierarchy = cv2.findContours(\n",
    "        combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    img_contours = img.copy()\n",
    "    cv2.drawContours(img_contours, contours, -1, (0, 255, 0), 1)\n",
    "    img_contours_rgb = cv2.cvtColor(img_contours, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Filtração dos contornos através de uma heuristica.\n",
    "    # Temos que pegar somente os contornos dos caracteres e ignorar o restante\n",
    "    predictions = []\n",
    "    h_img, w_img = img.shape[:2]\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # Heurística para filtrar caracteres\n",
    "        if heuristic(img, contour):\n",
    "            center_x = (x + w / 2) / w_img\n",
    "            center_y = (y + h / 2) / h_img\n",
    "            predictions.append(\n",
    "                Label(\n",
    "                    class_id=0,\n",
    "                    center_x=center_x,\n",
    "                    center_y=center_y,\n",
    "                    width=w / w_img,\n",
    "                    height=h / h_img,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Junta imagens de cada parte do processo até detectar os caracteres da placa\n",
    "    images_process = [\n",
    "        {\"image\": gray, \"title\": \"Grey\"},\n",
    "        {\"image\": blur, \"title\": \"Blur\"},\n",
    "        {\"image\": thresh, \"title\": \"Thresh binarização\"},\n",
    "        {\"image\": edges, \"title\": \"Edges\" + f\" {edge_method}\"},\n",
    "        {\"image\": img_contours_rgb, \"title\": \"Detected Contours\"},\n",
    "    ]\n",
    "\n",
    "    return (predictions, images_process)\n",
    "\n",
    "\n",
    "def heuristic(img: cv2.typing.MatLike, contour: cv2.typing.MatLike) -> bool:\n",
    "    \"\"\"\n",
    "    Verifica se os contornos representam um caractere naquela imagem\n",
    "\n",
    "    Args:\n",
    "        img (cv2.typing.MatLike): imagem\n",
    "        contour (cv2.typing.MatLike): contornos de um caracter da imagem\n",
    "\n",
    "    Returns:\n",
    "        bool: retorna se os contornar nessa imagem representam um caractere\n",
    "    \"\"\"\n",
    "\n",
    "    # Assumimos inicialmente que não é um caractere\n",
    "    is_character = False\n",
    "\n",
    "    # Obtemos um retângulo delimitador baseado no contorno\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "    # Métricas para validar se é o contorn de um caractere\n",
    "    character_aspect_ratio = w / h\n",
    "    character_area = w * h\n",
    "\n",
    "    h_img, w_img = img.shape[:2]\n",
    "    img_area = h_img * w_img\n",
    "\n",
    "    if (\n",
    "        0.2 < character_aspect_ratio < 0.8\n",
    "        and 0.02 * img_area < character_area < 0.15 * img_area\n",
    "    ):\n",
    "        is_character = True\n",
    "\n",
    "    return is_character\n",
    "\n",
    "\n",
    "def compute_iou(bbox1, bbox2):\n",
    "    \"\"\"\n",
    "    Calcula IoU entre dois retângulos (no formato YOLO normalizado).\n",
    "    \"\"\"\n",
    "    # Converter para coordenadas absolutas [xmin, ymin, xmax, ymax]\n",
    "    x1_min = bbox1.center_x - bbox1.width / 2\n",
    "    y1_min = bbox1.center_y - bbox1.height / 2\n",
    "    x1_max = bbox1.center_x + bbox1.width / 2\n",
    "    y1_max = bbox1.center_y + bbox1.height / 2\n",
    "\n",
    "    x2_min = bbox2.center_x - bbox2.width / 2\n",
    "    y2_min = bbox2.center_y - bbox2.height / 2\n",
    "    x2_max = bbox2.center_x + bbox2.width / 2\n",
    "    y2_max = bbox2.center_y + bbox2.height / 2\n",
    "\n",
    "    # Interseção\n",
    "    inter_xmin = max(x1_min, x2_min)\n",
    "    inter_ymin = max(y1_min, y2_min)\n",
    "    inter_xmax = min(x1_max, x2_max)\n",
    "    inter_ymax = min(y1_max, y2_max)\n",
    "\n",
    "    inter_w = max(0, inter_xmax - inter_xmin)\n",
    "    inter_h = max(0, inter_ymax - inter_ymin)\n",
    "    inter_area = inter_w * inter_h\n",
    "\n",
    "    # Áreas individuais\n",
    "    area1 = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "    area2 = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "\n",
    "    # IoU\n",
    "    union = area1 + area2 - inter_area\n",
    "    return inter_area / union if union > 0 else 0\n",
    "\n",
    "\n",
    "def evaluate_iou(detected_labels, true_labels, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calcula métricas médias de IoU e taxa de acerto (detections corretas).\n",
    "    \"\"\"\n",
    "    ious = []\n",
    "    matched = 0\n",
    "\n",
    "    for det in detected_labels:\n",
    "        best_iou = 0\n",
    "        for gt in true_labels:\n",
    "            iou = compute_iou(det, gt)\n",
    "            best_iou = max(best_iou, iou)\n",
    "        ious.append(best_iou)\n",
    "        if best_iou >= iou_threshold:\n",
    "            matched += 1\n",
    "\n",
    "    mean_iou = np.mean(ious) if ious else 0\n",
    "    precision = matched / len(detected_labels) if detected_labels else 0\n",
    "    recall = matched / len(true_labels) if true_labels else 0\n",
    "\n",
    "    return {\"mean_iou\": float(mean_iou), \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "\n",
    "def load_data(dir_path: str) -> Tuple[list[cv2.typing.MatLike], list[list[Label]]]:\n",
    "    \"\"\"\n",
    "    Carregue os dados da imagem e labels de um diretorio\n",
    "\n",
    "    Espera que as imagens e labels estejam ordenados numericamente,\n",
    "    e que as imagens estejam em arquivos .png e as labels em arquivos .txt.\n",
    "    Cada linha do arquivo .txt deve representar a label de um caractere da placa,\n",
    "    e ele devem estar separados por um espaço\n",
    "\n",
    "    Args:\n",
    "        dir_path (str): caminho para o diretorio com os dados\n",
    "\n",
    "    Returns:\n",
    "        Tuple[list[cv2.Mat], list[list[Label]]]: retorna imagens e labels encontrados no diretorio\n",
    "    \"\"\"\n",
    "\n",
    "    # Pegue o caminho para o diretório\n",
    "    dataset_dir_path = Path(dir_path)\n",
    "\n",
    "    # Separa as imagens dos labels\n",
    "    images_file_path = list(dataset_dir_path.glob(\"*.png\"))\n",
    "    labels_file_path = list(dataset_dir_path.glob(\"*.txt\"))\n",
    "\n",
    "    # Ordena os arquivos para ficarem na mesma ordem\n",
    "    images_file_path.sort()\n",
    "    labels_file_path.sort()\n",
    "\n",
    "    # Carregue as imagens\n",
    "    images: list[cv2.typing.MatLike] = []\n",
    "    for file_path in images_file_path:\n",
    "        image = cv2.imread(str(file_path), cv2.IMREAD_COLOR_RGB)\n",
    "        if image is not None:\n",
    "            images.append(image)\n",
    "\n",
    "    # Carregue as labels\n",
    "    labels: list[list[Label]] = []\n",
    "    for file_path in labels_file_path:\n",
    "        file_labels = []\n",
    "\n",
    "        # Pegamos uma label por linha (caractere da placa)\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                cid, cx, cy, w, h = line.split(\" \")\n",
    "                file_labels.append(\n",
    "                    Label(int(cid), float(cy), float(cx), float(h), float(w))\n",
    "                )\n",
    "\n",
    "        labels.append(file_labels)\n",
    "\n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Verifique os argumentos passados para o programa\n",
    "    # if len(sys.argv) not in [2, 3]:\n",
    "    #     sys.exit(\"Usage: python main.py data_directory\")\n",
    "    dataset_path = \"dataset\"\n",
    "\n",
    "    # Pegue as imagens e labels to dataset\n",
    "    # images, labels = load_data(sys.argv[1])\n",
    "    images, labels = load_data(dataset_path)\n",
    "\n",
    "    # Metricas para medir desempenho do programa\n",
    "    mean_iou = 0\n",
    "    mean_precision = 0\n",
    "    mean_recall = 0\n",
    "\n",
    "    for img, label in zip(images, labels):\n",
    "        # Localize os caracteres da placa\n",
    "        predictions, _ = localize_char_bbox(img)\n",
    "\n",
    "        # Verifique se as predições estão corretas\n",
    "        metrics = evaluate_iou(predictions, label)\n",
    "\n",
    "        # Se as métricas forem muito ruins, tenta outros métodos\n",
    "        if all(metric < 0.2 for metric in metrics.values()):\n",
    "            # Tenta método laplaciano\n",
    "            lap_predictions, _ = localize_char_bbox(img, edge_method=\"laplacian\")\n",
    "            lap_metrics = evaluate_iou(lap_predictions, label)\n",
    "\n",
    "            # Tenta método de sobel\n",
    "            sobel_predicitions, _ = localize_char_bbox(img, edge_method=\"sobel\")\n",
    "            sobel_metrics = evaluate_iou(sobel_predicitions, label)\n",
    "\n",
    "            # Pegue o melhor metodo\n",
    "            best_preds = lap_predictions\n",
    "            best_metrics = lap_metrics\n",
    "\n",
    "            if sobel_metrics[\"precision\"] > best_metrics[\"precision\"]:\n",
    "                best_preds = sobel_predicitions\n",
    "                best_metrics = sobel_metrics\n",
    "\n",
    "            if best_metrics[\"precision\"] > metrics[\"precision\"]:\n",
    "                predictions = best_preds\n",
    "                metrics = best_metrics\n",
    "\n",
    "        imgdraw = draw_bboxes(img, label, color=(0, 255, 0), thickness=1)\n",
    "        imgdraw = draw_bboxes(imgdraw, predictions, color=(0, 0, 255), thickness=1)\n",
    "\n",
    "        mean_iou += metrics[\"mean_iou\"]\n",
    "        mean_precision += metrics[\"precision\"]\n",
    "        mean_recall += metrics[\"recall\"]\n",
    "\n",
    "    n_samples = len(images)\n",
    "    print(\"Métricas finais:\")\n",
    "    print(f\"Mean IoU: {mean_iou / n_samples}\")\n",
    "    print(f\"Mean precision: {mean_precision / n_samples}\")\n",
    "    print(f\"Mean recall: {mean_recall / n_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas finais:\n",
      "Mean IoU: 0.8410459157011083\n",
      "Mean precision: 0.9327920267760423\n",
      "Mean recall: 0.8539627322974289\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
